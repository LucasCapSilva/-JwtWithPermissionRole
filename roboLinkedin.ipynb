{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrC11WFcEbVWcj2q6Gddn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasCapSilva/-JwtWithPermissionRole/blob/master/roboLinkedin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZSLelqbZBi6f"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "import pymongo\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myclient = pymongo.MongoClient('mongodb+srv://root:root@cluster0.sghjasx.mongodb.net/?retryWrites=true&w=majority')\n",
        "mydb = myclient['banco']\n",
        "mycol = mydb[\"banco\"]"
      ],
      "metadata": {
        "id": "bqOD_OYC4Be0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = []\n",
        "company = []\n",
        "location = []\n",
        "dados = []\n",
        "url= []\n",
        "link = ''"
      ],
      "metadata": {
        "id": "y9tkPJj8BlYS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_vacancies(tecnology,location_send,experience_level,num_page):\n",
        "  mycol.delete_many({\"tecnology\": tecnology})\n",
        "  text =\"\"\n",
        "  text_seniority_level =\"\"\n",
        "  text_employment_type =\"\"\n",
        "  text_job_function=\"\"\n",
        "  text_industries=\"\"\n",
        "  time_vacancies = \"\"\n",
        "  tech = tecnology\n",
        "  \n",
        "  for x in range(num_page):\n",
        "    title = []\n",
        "    company = []\n",
        "    location = []\n",
        "    url= []\n",
        "    link = 'https://www.linkedin.com/jobs/search?keywords='+tecnology+'&location'+location_send+'&locationId=&geoId=106057199&f_TPR=&f_E='+str(experience_level)+'&position=1&pageNum='+str(x)\n",
        "    res = requests.get(link) \n",
        "    soup = bs(res.text, 'lxml')\n",
        "    file = soup.find_all('h3', class_=\"base-search-card__title\") \n",
        "    for x in file:\n",
        "        title.append(x.text.strip())\n",
        "    file = soup.find_all('a', class_=\"base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]\")\n",
        "    for x in file:\n",
        "        url.append(x['href'])\n",
        "    file = soup.find_all('h4', class_=\"base-search-card__subtitle\")\n",
        "    for x in file:\n",
        "        company.append(x.text.strip())\n",
        "    file = soup.find_all('span', class_=\"job-search-card__location\")\n",
        "    for x in file:\n",
        "        location.append(x.text.strip())\n",
        "    for index, val in enumerate(title):\n",
        "      res = requests.get(url[index]) \n",
        "      soup = bs(res.text, 'lxml')\n",
        "      text = \"\"\n",
        "      linkVagas = url[index]\n",
        "      for row in soup.find_all('ul', class_=\"description__job-criteria-list\"):\n",
        "          text_seniority_level = row('span')[0].text.strip()\n",
        "      for row in soup.find_all('ul', class_=\"description__job-criteria-list\"):\n",
        "          text_employment_type = row('span')[1].text.strip()\n",
        "      for row in soup.find_all('ul', class_=\"description__job-criteria-list\"):\n",
        "          text_job_function = row('span')[2].text.strip()\n",
        "      for row in soup.find_all('ul', class_=\"description__job-criteria-list\"):\n",
        "          text_industries = row('span')[3].text.strip()\n",
        "      file = soup.find_all('span', class_=\"posted-time-ago__text posted-time-ago__text--new topcard__flavor--metadata\")\n",
        "      for x in file:\n",
        "          time_vacancies = x.text.strip()\n",
        "      now = datetime.now()\n",
        "      search_date = now.strftime(\"%d/%m/%Y\")\n",
        "      dados.append({'title':title[index],'search_date':search_date,'tecnology': tecnology,'hardSkills':[],'linkVacancie':linkVagas, 'seniorityLevel':text_seniority_level,'jobFunction':text_job_function, 'employmentType':text_employment_type, 'industries':text_industries,'timeVacancies':time_vacancies ,'content':text, 'company':company[index] , 'location':location[index] })\n",
        "  for dado in dados:\n",
        "    is_not_content= True\n",
        "    while is_not_content:\n",
        "      if(dado['content'] == '' ):\n",
        "        res = requests.get(dado['linkVacancie'])\n",
        "        soup = bs(res.text, 'lxml')\n",
        "        text = \"\"\n",
        "        file = soup.find_all('div', class_=\"show-more-less-html__markup\")\n",
        "        for x in file:\n",
        "            text = text + x.text.strip()\n",
        "            dado['content'] = text\n",
        "        if(text != ''):\n",
        "          is_not_content = False\n",
        "      else:\n",
        "        is_not_content = False"
      ],
      "metadata": {
        "id": "wdOmU6xVrJIK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_vacancies('java','brazil',3,1)"
      ],
      "metadata": {
        "id": "5itoKmyeqGew"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dados)"
      ],
      "metadata": {
        "id": "eve_O7_oCzAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff75053-7a3d-4bcb-948a-f707ecef0473"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados[23]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HamqOQaZLxVp",
        "outputId": "06e998a0-4290-4b87-e122-00f1328fe4a8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'Junior Maintenance Engineer',\n",
              " 'search_date': '13/12/2022',\n",
              " 'tecnology': 'java',\n",
              " 'hardSkills': [],\n",
              " 'linkVacancie': 'https://br.linkedin.com/jobs/view/junior-maintenance-engineer-at-shape-3351692048?refId=mczCG8LizuFA9%2FzTcpMGug%3D%3D&trackingId=YPm8IKqQCqXcBPI4KWvGZg%3D%3D&position=24&pageNum=0&trk=public_jobs_jserp-result_search-card',\n",
              " 'seniorityLevel': 'Júnior',\n",
              " 'jobFunction': 'Tecnologia da informação, Consultoria e Engenharia',\n",
              " 'employmentType': 'Tempo integral',\n",
              " 'industries': 'Serviços e consultoria de TI, Desenvolvimento de software e Tecnologia, Informação e Internet',\n",
              " 'timeVacancies': 'Há 4 horas',\n",
              " 'content': \"A Maintenance Engineer here at Shape works closely with a multidisciplinary Agile team to build cutting-edge advanced analytics solutions. These solutions will generate insights from our connected data, enabling the team to advance the data-driven decision-making capabilities of our enterprise. This role requires understanding of engineering, troubleshooting and monitoring of rotating equipment. You will work closely with Data Scientists and Product Owners to ensure business value and quality.We are looking for someone who can:Contribute to develop advanced analytics solutions to Predictive Analysis for vibration, thermography, oil analysis, lubrication and other metrics.Receive and filter Predictive Analysis Results to be discussed or shared to Reliability’s Specialists Team, helping to coordinate and/or request forward future corrective actions on the equipment.Ensure the operation reliability and its performance (gas turbines, steam turbines, gas compressors and pumps) by acting as technical referent to assist the analysis of the results, elaboration of proper root cause assessments and issuance of technical review and recommendation.Give guidance and assistance with regards to turbo machinery offshore equipment maintenance issues and failures.Foster close cooperation across data scientists and data engineers, encouraging cross-training and mutual support.Value assurance: work with business process owners to validate model outputs, construct appropriate trainings, tune models and ensure value created from models.Problem framing: participate in problem framing together with business owners, data scientists and other engineers for identified opportunities.RequirementsEducation: complete degree in Mechanical Engineering. Experience working in reliability or maintenance activities focused on condition-based monitoring. Strong collaborator with cross-functional teams from tech, design, and business.To be available to work at our office, at Rio de Janeiro, RJ.Advanced/Fluent English.Desirable Qualifications:Experience working with predictive technologies and digital projects.Experience in O&G.CREA is desireble.Elaboration of analysis and notification of data using PIAF and PI systems.BenefitsProfit Sharing Plan: Variable according to your daily performance and the company's total profits;Premium Medical Plan: expendable for dependents, without co-participation or payroll deduction for you or your legal dependents;Dental Plan: expendable for dependents, without co-participation or payroll deduction for you or your legal dependents;Life Insurance: no co-payment or payroll deduction;Gympass;Meal & Food Tickets (VA/VR): Flash flexible benefits card;Corporate Education incentive: We at Shape encourage your professional growth and development, through educational incentives that will be included in your Individual Development Plan (IDP);Daycare allowance: for dependents up to 5 years old;Mentoring: with Shape leadership, aiming career development.Referral program;Accelerated career growth and more!\",\n",
              " 'company': 'Shape',\n",
              " 'location': 'Rio de Janeiro, Rio de Janeiro, Brazil'}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in dados:\n",
        "    mycol.insert_one(x)"
      ],
      "metadata": {
        "id": "zh664TZz4Lvk"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mycol.find_one())"
      ],
      "metadata": {
        "id": "HsDspJb_4_sV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}